# Project Orbit Subagents

Specialized AI assistants for complex workflows with parallel execution support.

## Directory Structure

```
.cursor/agents/
├── README.md (this file)
├── schema-analyzer.md              # Phase 1: DB schema verification
├── rabbit-tracer.md                # Phase 1: RabbitMQ flow tracing
├── tdd-planner.md                  # Phase 2: Test-first planning
├── risk-analyzer.md                # Phase 2: Pre-implementation risk assessment
├── code-reviewer.md                # Phase 3: Code quality review
├── test-validator.md               # Phase 3: Test coverage validation
└── regression-detector.md          # Phase 3: Cross-feature impact analysis
```

**Note:** JIRA context analysis is now a skill (not a subagent), located at `.cursor/skills/jira-context-analysis/SKILL.md`

---

## Phase 1: Foundation (Triple-Check Context Protocol)

### 1. ~~`jira-context-analyzer`~~ → **Now a Skill (Inline Execution)**
**Status:** Skill (NOT a subagent)  
**Location:** `.cursor/skills/jira-context-analysis/SKILL.md`  
**Why:** Schema and RabbitMQ analyzers DEPEND on JIRA context to know what to analyze. Running JIRA as a subagent would create false parallelism (main agent sits idle waiting for JIRA before parsing context).  
**When to use:** Inline during `/start` command (first step)  
**Tools:** Jira MCP, Google Drive MCP (used directly by main agent)  
**Output:** 4-part Context Analysis Report (generated by main agent)
- PRD/Primary Document Summary
- JIRA Hierarchy Analysis (Main Ticket + Sub-Task Breakdown)
- Linked Asset Analysis
- Final Synthesized Requirements
- **Parsed context:** Entities, service, exchange/routing key for subagents

**Main agent execution (inline):**
```javascript
// Main Agent uses jira-context-analysis skill (25-35 seconds)
1. Jira MCP: fetch ticket + sub-tasks + comments
2. GDrive MCP: fetch PRD (if link found)
3. Synthesize Context Analysis Report
4. Parse requirements → extract entities, service, exchange/routing key
5. Save: docs/<TICKET_ID>/context_analysis_report.md

// Then launch parallel subagents with parsed context
[
  Task(schema-analyzer, entities: [from parse]),
  Task(rabbit-tracer, service: [from parse])
]
```

**Reference:** `.cursor/skills/jira-context-analysis/SKILL.md` (skill guide for main agent)

### 2. `schema-analyzer`
**Purpose:** Verify DB schemas and recommend indexes  
**When to use:** When DB changes are suspected (during discovery)  
**Tools:** MariaDB MCP, MongoDB MCP, Read, Grep  
**Output:** Schema Comparison Report
- MariaDB/MongoDB schema details
- Schema mismatches (code vs DB)
- Index recommendations (Universal Indexing Framework)

**Invocation example:**
```javascript
Task(
  subagent_type="generalPurpose",
  prompt="Read and execute .cursor/agents/schema-analyzer.md for entities: contacts, practices. Compare with models at: src/models/",
  description="Analyze DB schemas"
)
```

### 3. `rabbit-tracer`
**Purpose:** Trace RabbitMQ producer-consumer flows  
**When to use:** When RabbitMQ or cross-service messaging is involved  
**Tools:** Grep/SemanticSearch, Read, Jira/GDrive/DB MCPs  
**Output:** Message Flow Report
- Producer → Exchange/Routing Key/Queue → Consumer
- Payload contract comparison
- Schema mismatches
- Binding verification

**Invocation example:**
```javascript
Task(
  subagent_type="generalPurpose",
  prompt="Read and execute .cursor/agents/rabbit-tracer.md. Producer: src/services/ContactService.js. Exchange: contact_events. Routing Key: contact.updated",
  description="Trace RabbitMQ flow"
)
```

---

## Phase 2: Intelligent Planning

### 4. ~~`implementation-planner`~~ → **Now a Skill (Inline Execution)**
**Status:** Skill (NOT a subagent)  
**Location:** `.cursor/skills/implementation-planning/SKILL.md`  
**When to use:** After TDD Blueprint and Risk Assessment complete (during `/plan` command)  
**Execution:** Main agent runs this skill inline (no delegation)  

**Why it's a skill:**
- Synthesizes existing reports (doesn't gather new data)
- No MCP usage required
- Main agent already has all context
- Correct sequencing: runs AFTER TDD/Risk subagents complete
- Lower latency than subagent delegation

**Output:** Technical Implementation Plan with 18-aspect table (problem, solution, architecture, DB, APIs, security, performance, rollback)

### 5. `tdd-planner`
**Purpose:** Design comprehensive test suite (Red phase)  
**When to use:** After discovery, before implementation (via `/plan` command)  
**Tools:** Read, Grep, SemanticSearch  
**Output:** TDD Blueprint
- Test suite structure (unit + integration)
- Coverage map (requirements → tests)
- Implementation guidance (Green phase)
- Refactor checklist
- Compliance verification

**Invocation example:**
```javascript
Task(
  subagent_type="generalPurpose",
  prompt="Read and execute .cursor/agents/tdd-planner.md. Context: Requirements from Context Analysis Report, Discovery Report at docs/CSIQ-12043/discovery_report.md",
  description="Generate TDD Blueprint"
)
```

### 6. `risk-analyzer`
**Purpose:** Assess risks before implementation  
**When to use:** After discovery, parallel with TDD planning  
**Tools:** Read, Grep, SemanticSearch  
**Output:** Risk Assessment Report
- Readiness: Green/Yellow/Red
- Breaking changes (API, DB, Message, Integration)
- Performance risks (indexes, N+1, data volume)
- Security & compliance risks (HIPAA, auth, validation)
- Operational risks (deployment, rollback, monitoring)
- Mitigation checklist

**Invocation example:**
```javascript
Task(
  subagent_type="generalPurpose",
  prompt="Read and execute .cursor/agents/risk-analyzer.md. Context: Discovery Report at docs/CSIQ-12043/discovery_report.md, Ticket: CSIQ-12043",
  description="Assess implementation risks"
)
```

---

## Phase 3: Quality Assurance

### 7. `code-reviewer`
**Purpose:** Hostile QA code review  
**When to use:** After implementation (via `/finish` command)  
**Tools:** Read, Grep  
**Output:** Code Review Report
- Post-Implementation Checklist (✅/❌)
- N+1 query violations
- Missing Joi validation
- HIPAA compliance issues
- Performance issues
- Pattern violations
- Final verdict: PASS/FAIL

**Invocation example:**
```javascript
Task(
  subagent_type="generalPurpose",
  prompt="Read and execute .cursor/agents/code-reviewer.md. Context: Changed files: src/controllers/ContactController.js, src/services/ContactService.js, src/repositories/ContactRepository.js",
  description="Review code quality"
)
```

### 8. `test-validator`
**Purpose:** Validate test coverage and quality  
**When to use:** After implementation (via `/finish` command, parallel with code-reviewer)  
**Tools:** Read, Grep  
**Output:** Test Validation Report
- Test existence (unit + integration)
- Test execution status
- Test quality (happy path, edge cases, errors)
- Coverage metrics (line, branch, function)
- TDD Blueprint compliance
- Final verdict: PASS/FAIL

**Invocation example:**
```javascript
Task(
  subagent_type="generalPurpose",
  prompt="Read and execute .cursor/agents/test-validator.md. Context: Changed files: src/services/ContactService.js. TDD Blueprint: docs/CSIQ-12043/tdd_blueprint.md",
  description="Validate test coverage"
)
```

### 9. `regression-detector`
**Purpose:** Identify cross-feature impact  
**When to use:** Before final approval (via `/finish` command, part of sentinel)  
**Tools:** Grep, SemanticSearch, Read  
**Output:** Regression Impact Report
- Direct dependencies (function calls, imports, inheritance)
- Indirect dependencies (DB schema, API contracts, constants, messages)
- Risk assessment (high/medium/low risk features)
- Existing test coverage for dependent code
- Recommended regression tests

**Invocation example:**
```javascript
Task(
  subagent_type="generalPurpose",
  prompt="Read and execute .cursor/agents/regression-detector.md. Context: Changed files: src/services/ContactService.js. Changed functions: getContacts(), updateContact(). Schema changes: Added preferred_contact_method column",
  description="Detect regression impact"
)
```

---

## Workflow Integration

### `/start` Command (Init and Discovery)
**Sequential then Parallel execution:**
1. **Main agent inline:** JIRA context analysis (25-35 seconds)
   - Fetch ticket + sub-tasks + PRD using MCPs
   - Synthesize Context Analysis Report
   - Parse requirements → identify entities, service, exchange/routing key

2. **Parallel subagents** (with context from step 1):
   - `schema-analyzer` (if DB changes identified)
   - `rabbit-tracer` (if RabbitMQ identified)

→ Discovery Report → User confirmation → Risk + TDD planning

**Performance:**
- Before (false parallelism): 30-40s (JIRA subagent, main idle) + 20-30s (schema+rabbit) = 50-70s
- After (true parallelism): 25-35s (JIRA inline, main working) + 20-30s (schema+rabbit) = 45-65s
- **Improvement:** ~10% faster + no idle time + true parallelism

### After Discovery (Planning)
**Parallel execution (2 subagents):**
1. `risk-analyzer` (assess risks)
2. `tdd-planner` (design tests)

→ Wait for completion → **Main agent runs `implementation-planning` skill** (synthesize all reports) → User approval → Implementation

### `/finish` Command (Review and Sentinel)
**Parallel execution:**
1. `code-reviewer` (code quality)
2. `test-validator` (test coverage)

→ If PASS → `regression-detector` → Rulebook update → Done

---

## Best Practices

### Parallel Execution (CRITICAL)
Always run **independent** subagents in **parallel** (single message, multiple Task calls) for faster context gathering:

```javascript
// CORRECT: Parallel execution for INDEPENDENT subagents
// (Both schema-analyzer and rabbit-tracer can run simultaneously)
[
  Task(subagent_type="generalPurpose", model="fast", prompt="...schema-analyzer... for entities: contacts, practices. Verbosity: full", description="Analyze DB"),
  Task(subagent_type="generalPurpose", model="fast", prompt="...rabbit-tracer... Service: service-csiq-cdr. Verbosity: full", description="Trace RabbitMQ")
]

// INCORRECT: Sequential execution when they're independent (PERFORMANCE FAILURE)
Task(...schema-analyzer...) → wait → Task(...rabbit-tracer...)

// NOTE: JIRA context is gathered INLINE by main agent (not a subagent)
// Because schema-analyzer and rabbit-tracer DEPEND on JIRA context
Main Agent Inline:
  1. Fetch JIRA context (25-35s)
  2. Parse → entities, service, exchange
  3. Launch parallel: [schema-analyzer, rabbit-tracer] ← TRUE PARALLELISM
```

**Why parallel matters:**
- **Speed:** Reduces wall-clock time by 40-50% for dependent analyses
- **Cost:** Fast model for mechanical tasks reduces cost by 90%
- **User experience:** Faster feedback loop
- **Honesty:** No false parallelism (dependencies are explicit)

### Context Passing
Subagents are **isolated** (no access to parent context). Always provide:
- Ticket ID (e.g. `CSIQ-12043`)
- File paths (e.g. `docs/CSIQ-12043/discovery_report.md`)
- Entity names (e.g. `contacts, practices`)
- Service names (e.g. `ContactService`)
- Exchange/routing key names (e.g. `contact_events`, `contact.updated`)
- **Verbosity level:** `summary` or `full` (default: `full`)

### Model Selection (NEW - Cost Optimization)
Choose the right model for each subagent:

**Use `model: "fast"` (1/10th cost, 2-3x faster):**
- `schema-analyzer` – Schema fetching is mechanical
- `rabbit-tracer` – Message flow tracing is largely search + compare
- Any subagent doing primarily **data fetching or pattern matching**

**Use `model: "default"` (better reasoning):**
- `jira-context-analyzer` – Requires synthesis across multiple sources
- `tdd-planner` – Requires test design reasoning
- `risk-analyzer` – Requires risk assessment reasoning
- `code-reviewer` – Requires pattern detection and code analysis
- `test-validator` – Requires quality assessment
- `regression-detector` – Requires dependency analysis and impact assessment

**Example:**
```javascript
Task(subagent_type="generalPurpose", model="fast", prompt="...schema-analyzer...", description="Analyze DB")  // Fast model
Task(subagent_type="generalPurpose", model="default", prompt="...tdd-planner...", description="Plan tests")  // Default model
```

### Verbosity Control (NEW - Token Optimization)
Control output size based on need:

**Use `verbosity: summary` when:**
- You only need high-level results (e.g., counts, status, critical issues)
- Token budget is limited
- Speed is more important than detail

**Use `verbosity: full` (default) when:**
- You need complete analysis for decision-making
- Creating reports for user review
- Debugging or investigating issues

**Example:**
```javascript
Task(subagent_type="generalPurpose", prompt="...schema-analyzer... Verbosity: summary", ...)  // Quick check
Task(subagent_type="generalPurpose", prompt="...schema-analyzer... Verbosity: full", ...)     // Full report
```

### Error Handling
Subagents will explicitly state if:
- MCP is unavailable
- Required context is missing
- Critical information cannot be verified

If a subagent **cannot proceed**, address the issue before continuing (e.g. fix MCP, provide missing context).

**NEW: MCP Fallback Strategies**

All subagents now include **fallback strategies** when MCPs are unavailable:

1. **Jira/GDrive unavailable:**
   - Ask user for ticket details / PRD content
   - Continue with manual context (HIGH RISK warning)
   
2. **DB MCPs unavailable:**
   - Option 1: Use code models only (user approval required, HIGH RISK)
   - Option 2: Ask user for schema dump
   - Option 3: Stop and wait for MCP (default)

3. **Session MCP Status Cache:**
   - `/init` command now caches MCP availability for the session
   - Subagents check cache before attempting MCP calls
   - If MCP is ❌, use fallback immediately (no repeated connection attempts)

### Fallback to Manual
All skills have **fallback logic** for manual analysis if subagents are unavailable. Prefer subagents for:
- Faster execution (parallel processing)
- Consistent quality (standardized prompts)
- Context isolation (no interference with parent agent)

---

## MCP Dependencies

### Required MCPs
- **Jira MCP:** For `jira-context-analyzer`
- **Google Drive MCP:** For `jira-context-analyzer` (PRD fetching)
- **MariaDB MCP:** For `schema-analyzer`
- **MongoDB MCP:** For `schema-analyzer`

### Graceful Degradation
If MCPs are unavailable:
- `jira-context-analyzer`: Will state "MCP unavailable, cannot fetch ticket" and stop
- `schema-analyzer`: Will state "DB MCP unavailable, cannot verify schema" and stop
- `rabbit-tracer`: Will continue with code-only analysis, flag missing DB/MCP verification

---

## Performance

### Execution Time
- **Phase 1 (parallel):** ~30-60 seconds for all 3 subagents
- **Phase 2 (parallel):** ~20-40 seconds for both subagents
- **Phase 3 (parallel):** ~30-50 seconds for all 3 subagents

### Cost Optimization (UPDATED)
- **Model selection:** Use `model: "fast"` for mechanical subagents (schema-analyzer, rabbit-tracer) → 90% cost reduction
- **Verbosity control:** Use `verbosity: summary` when full details aren't needed → 50-70% token reduction
- **Report caching:** Commands now cache subagent outputs in `docs/<TICKET_ID>/` → Eliminates redundant subagent invocations across `/start`, `/plan`, `/finish`
- **Parallel execution:** Reduces total wall-clock time by 50-70%

**Estimated savings for typical workflow:**
- `/start` with 3 parallel subagents (2 fast, 1 default): **~60% cost reduction** vs all default sequential
- `/plan` reusing cached reports + parallel execution: **~40% cost reduction**
- `/finish` with parallel review + cached reports: **~50% cost reduction**

**Total workflow savings:** ~50-60% cost reduction with optimizations

---

## Troubleshooting

### "Subagent returned incomplete report"
→ Check if MCP was unavailable (Jira, GDrive, DB)  
→ Verify all required context was provided in prompt

### "Cannot invoke subagent"
→ Check Task tool syntax (use `subagent_type="generalPurpose"`)  
→ Verify `.cursor/agents/<subagent-name>.md` file exists

### "Subagent takes too long"
→ Normal for comprehensive analysis (30-60s)  
→ Check if running sequentially instead of parallel

### "MCP server stored: false"
→ See `.cursor/rules/troubleshooting.mdc` for MCP startup fixes  
→ Subagents will gracefully fail and report MCP unavailability

---

## Future Enhancements

### Potential Phase 4 (Not Yet Implemented)
- **deployment-planner:** Pre-deployment checklist and coordination
- **perf-analyzer:** Performance profiling and optimization
- **security-scanner:** OWASP/HIPAA vulnerability scanning

### Customization
To add a new subagent:
1. Create `.cursor/agents/<name>.md` with YAML frontmatter
2. Define clear task, tools, output format, error handling
3. Update relevant skills/commands to invoke it
4. Add to this README with usage examples

---

## Support

For questions or issues with subagents:
- Check skill/command files for invocation examples
- Review individual subagent `.md` files for detailed instructions
- Consult `.cursor/rules/troubleshooting.mdc` for MCP issues
